---
title: "Benchmarking against DESeq2 and edgeR"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Benchmarking against DESeq2 and edgeR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# A Review of MoR and TMM Normalization

## Set Up

Let $y_{i,g}$ denote the observed count in a sample $i \in \mathcal{I}$ (with $n_i = |\mathcal{I}|$) for a gene $g \in \mathcal{G}$ (with $n_g = |\mathcal{G}|$) realized from a particular negative binomial distribution:

$$\begin{aligned}
    Y_{i,g} &\sim \text{NegBinom}(\mu_{i,g}, \phi_{g}) \\
    \mu_{i,g} &= \eta_{i,g} \cdot \rho_{i}
\end{aligned}$$

Where $\eta_{i,g}$ denotes the true magnitude of expression and $\rho_{i}$ denotes the "size factor" that scales this expression from its ground-truth.

## `DESeq2`'s Median of Ratios

We first focus on a particular gene $g$ and compare the observed count for a sample $i$ to the geometric average of counts across samples to get a ratio $R_{i,g}$:

$$
    R_{i,g} = \frac{ y_{i,g} }{( \prod_{i \in \mathcal{I}} y_{i,g} )^{ \frac{1}{n_i} } }
$$

We then take the median of these ratios to get our size factor estimates!

$$
    \hat{s}_{i} = \underset{g \in \mathcal{G}}{\text{median }} R_{i,g}
$$

## `edgeR`'s Trimmed Mean of M Values

We first "normalize" the observed count profile for a sample $i$ by the total number of counts $N_i = \sum_{g \in \mathcal{G}} y_{i,g}$ in order to get proportions:

$$
    y'_{i,g} = \frac{y_{i,g}}{N_i}
$$

We next select a reference sample $i^{\dagger} \in \mathcal{I}$ and compute both the ratio of log-transformed proportions and their weights:

$$\begin{aligned}
    R_{i,g} &= \frac{\log_2 y'_{i,g}}{\log_2 y'_{i^{\dagger}, g}} \\
    w_{i,g} &= \frac{ N_i - Y_{i,g} }{ N_i Y_{i,g} } + \frac{ N_{i^{\dagger}} - Y_{i^{\dagger},g} }{ N_{i^{\dagger}} Y_{i^{\dagger},g} }
\end{aligned}$$

We then filter the genes to a subset $\mathcal{G}'_i \subset \mathcal{G}$ by symmetrically "trimming" away the smallest and largest ratios for a sample $i$ to XX% of the original number (defaults to 70%).

We finally compute the size factor by taking the weighted average of these ratios and raising it to the second power:

$$
    \log_2 \hat{s}_i = \frac{ \sum_{g \in \mathcal{G}'_i} w_{i,g} R_{i,g} }{ \sum_{g \in \mathcal{G}'_i} w_{i,g} }
$$

# Benchmarking Size Factor Estimation

```{r, echo = FALSE}
suppressPackageStartupMessages({
    library(reformulas)
    library(disize)
    library(DESeq2)
    library(edgeR)
    library(dplyr)
    library(purrr)
    library(tidyr)
    library(future)
    library(future.apply)
    library(ggplot2)
})

future::plan(
    future::multisession, 
    workers = parallel::detectCores() / 2
)
```

```{r, echo = FALSE}
split_formula <- function(design_formula) {
    # Extract terms
    terms <- attr(terms(design_formula), "term.labels")

    # Identify random effects
    re <- grepl("\\| ", terms)

    fixed <- NULL
    if (length(terms[!re]) != 0) {
        fixed <- formula(paste0(" ~ 0 + ", paste(terms[!re], collapse = " + ")))
    }

    random <- NULL
    if (length(terms[re]) != 0) {
        random <- stats::formula(paste0(
            " ~ 0 + ",
            paste(terms[re], collapse = " + ")
        ))
    }

    list(
        formula = design_formula,
        fixed = fixed,
        random = random
    )
}

simulate_dataset <- function(design_formula, data, n_genes, sparsity, sd) {
    # Simulate inverse overdispersion factors
    iodisps <- rlnorm(n_genes, log(10), 0.001)

    # Split design formula
    design <- split_formula(design_formula)

    # Construct model matrices
    if (!is.null(design$fixed)) {
        fe_design <- model.matrix(design$fixed, data)
    } else {
        fe_design <- matrix(nrow = nrow(data), ncol = 0L)
    }

    if (!is.null(design$random)) {
        remm <- reformulas::mkReTrms(
            bars = reformulas::findbars(design$random),
            fr = data,
            calc.lambdat = FALSE,
            sparse = TRUE
        )
        re_design <- Matrix::t(remm$Zt)
    } else {
        remm <- list(
            Ztlist = list(matrix(nrow = nrow(data), ncol = 0L))
        )
        re_design <- matrix(nrow = nrow(data), ncol = 0L)
    }

    # Simulate size factors
    size_factors <- runif(length(levels(data$batch_id)), 0.1, 1.0) |> 
        setNames(levels(data$batch_id))
    
    # Simulate counts
    counts <- sapply(1:n_genes, function(i) {
        # Simulate covariate coefficients
        intercept <- rnorm(1)
        fe_coefs <- rbinom(ncol(fe_design), 1, 1 - sparsity) * rnorm(ncol(fe_design), sd = sd)
        re_coefs <- lapply(lapply(remm$Ztlist, nrow), function(n_rows) {
            #
            rbinom(1, 1, 1 - sparsity) * rnorm(n_rows, sd = sd)
        }) |>
            unlist()

        # Compute realized magnitude
        log_mu <- (intercept + 
            fe_design %*% fe_coefs + 
            re_design %*% re_coefs + 
            log(size_factors[data$batch_id])) |>
            as.vector()

        # Simulate counts
        rnbinom(nrow(data), mu = exp(log_mu), size = iodisps[i])
    })

    # Cast to integers
    mode(counts) <- "integer"

    list(
        counts = counts, 
        metadata = data, 
        size_factors = log(size_factors / sum(size_factors) * length(size_factors))
    )
}

get_disize <- function(dataset, design_formula) {
    disize_sf <- disize::disize(
        design_formula,
        dataset$counts,
        dataset$metadata,
        "batch_id",
        n_feats = ncol(dataset$counts),
        verbose = 1L,
        n_threads = 2
    )

    disize_sf
}
get_deseq2 <- function(dataset) {
    dds <- DESeq2::DESeqDataSetFromMatrix(
        countData = t(dataset$counts),
        colData = dataset$metadata,
        design = ~ 1
    )
    dds <- DESeq2::estimateSizeFactors(dds)

    # Extract size factors
    deseq2_sf <- DESeq2::sizeFactors(dds)

    # Scale for comparisons
    log(deseq2_sf / sum(deseq2_sf) * length(deseq2_sf))
}
get_edger <- function(dataset) {
    dds <- edgeR::DGEList(counts = t(dataset$counts))
    dds <- edgeR::calcNormFactors(dds, method = "TMM")

    # Extract size factors
    edger_sf <- dds$samples$norm.factors

    # Scale for comparisons
    log(edger_sf / sum(edger_sf) * length(edger_sf))
}

run_benchmark <- function(n_sims, sim_pars, design_formula, data) {
    # Run benchmarks
    benchmark <- sim_pars |>
        dplyr::mutate(d = purrr::pmap(list(n_genes, sparsity, sd), function(n_genes, sparsity, sd) {
            errors <- future.apply::future_replicate(
                n = n_sims, 
                expr = {
                # Simulate dataset
                dataset <- simulate_dataset(design_formula, data, n_genes, sparsity, sd)

                # Estimate size factors
                disize_sf <- get_disize(dataset, design_formula)
                deseq2_sf <- get_deseq2(dataset)
                edger_sf <- get_edger(dataset)

                # Compute error on log-scale
                tibble::tibble(
                    disize = sqrt(sum((dataset$size_factors - disize_sf)^2)),
                    deseq2 = sqrt(sum((dataset$size_factors - deseq2_sf)^2)),
                    edger = sqrt(sum((dataset$size_factors - edger_sf)^2))
                )
                },
                simplify = FALSE
            )

            # Denote simulation ID
            dplyr::bind_rows(errors) |>
                tibble::rowid_to_column("sim_id")
        })) |>
        tidyr::unnest(d) |> 
        dplyr::mutate(
            disize_vs_disize = disize / disize,
            deseq2_vs_disize = deseq2 / disize,
            edger_vs_disize = edger / disize
        ) |>
        tidyr::pivot_longer(
            cols = c(disize_vs_disize, deseq2_vs_disize, edger_vs_disize),
            names_to = "comparison",
            values_to = "relative_error"
        ) |>
        dplyr::group_by(setting_id, comparison) |>
        dplyr::mutate(
            q95 = quantile(relative_error, 0.95),
            q75 = quantile(relative_error, 0.75),
            q60 = quantile(relative_error, 0.60),
            q40 = quantile(relative_error, 0.40),
            q25 = quantile(relative_error, 0.25),
            q5 = quantile(relative_error, 0.05)
        )
    
    benchmark
}

plot_benchmark <- function(benchmark, title, design_formula) {
    the_plot <- ggplot(benchmark, aes(x = n_genes, color = comparison, fill = comparison)) +
        geom_ribbon(aes(ymin = q5, ymax = q95), alpha = 0.25) +
        geom_ribbon(aes(ymin = q25, ymax = q75), alpha = 0.25) +
        geom_ribbon(aes(ymin = q40, ymax = q60), alpha = 0.25) +
        scale_y_log10() +
        facet_wrap(
            ncol = 1,
            facets = vars(sparsity),
            labeller = labeller(
                sparsity = function(x) paste0("Sparsity: ", x)
            )) +
        labs(
            title = title,
            subtitle = paste("Design Formula:", paste(as.character(design_formula), collapse = " ")),
            x = "# of Genes", 
            y = "Relative Error",
            color = "Method",
            fill = "Method") +
        scale_fill_discrete(
            labels = c("DESeq2", "disize", "edgeR")
        ) +
        scale_color_discrete(
            labels = c("DESeq2", "disize", "edgeR")
        ) +
        theme_classic()
    
    the_plot
}
```

```{r, echo = FALSE}
# Simulating settings
n_sims <- 5L
sim_pars <- expand.grid(
    "n_genes" = c(10000L, 20000L, 30000L),
    "sparsity" = c(0.20, 0.40, 0.60, 0.80),
    "sd" = c(1.0)
) |>
    tibble::rowid_to_column("setting_id")
```

## A Trivial Setting

```{r, echo = FALSE}
design_formula <- ~ (1 | donor_id)

n_donors <- 6L
data <- data.frame(
    donor_id = as.factor(1:n_donors),
    batch_id = as.factor(1:n_donors)
)

message("Design Data:")
gt::gt(data)

# Run and plot benchmark
benchmark <- run_benchmark(n_sims, sim_pars, design_formula, data)
```

```{r, echo = FALSE, fig.height=11}
plot_benchmark(benchmark, "A Trivial Setting", design_formula)
```


## Comparing Two Conditions

```{r, echo = FALSE}
design_formula <- ~ cond_id + (1 | donor_id)

n_donors <- 6L
data <- data.frame(
    donor_id = as.factor(1:n_donors),
    cond_id = cut(1:n_donors, 2),
    batch_id = as.factor(1:n_donors)
)
levels(data$cond_id) <- letters[1:2]

message("Design Data:")
gt::gt(data)

# Run and plot benchmark
benchmark <- run_benchmark(n_sims, sim_pars, design_formula, data)
```

```{r, echo = FALSE, fig.height=11}
plot_benchmark(benchmark, "Comparing Two Conditions", design_formula)
```


# Benchmarking Impact on Downstream Differential Expression Analysis

