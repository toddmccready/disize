[{"path":"https://toddmccready.github.io/disize/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 disize authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":[]},{"path":"https://toddmccready.github.io/disize/articles/benchmarking.html","id":"set-up","dir":"Articles","previous_headings":"A Review of MoR and TMM Normalization","what":"Set Up","title":"Benchmarking against DESeq2 and edgeR","text":"Let y_{,g} denote observed count sample \\\\mathcal{} (n_i = |\\mathcal{}|) gene g \\\\mathcal{G} (n_g = |\\mathcal{G}|) realized particular negative binomial distribution: \\begin{aligned}     Y_{,g} &\\sim \\text{NegBinom}(\\mu_{,g}, \\phi_{g}) \\\\     \\mu_{,g} &= \\eta_{,g} \\cdot \\rho_{} \\end{aligned} \\eta_{,g} denotes true magnitude expression \\rho_{} denotes “size factor” scales expression ground-truth.","code":""},{"path":"https://toddmccready.github.io/disize/articles/benchmarking.html","id":"deseq2s-median-of-ratios","dir":"Articles","previous_headings":"A Review of MoR and TMM Normalization","what":"DESeq2’s Median of Ratios","title":"Benchmarking against DESeq2 and edgeR","text":"first focus particular gene g compare observed count sample geometric average counts across samples get ratio R_{,g}: R_{,g} = \\frac{ y_{,g} }{( \\prod_{\\\\mathcal{}} y_{,g} )^{ \\frac{1}{n_i} } } take median ratios get size factor estimates! \\hat{s}_{} = \\underset{g \\\\mathcal{G}}{\\text{median }} R_{,g}","code":""},{"path":"https://toddmccready.github.io/disize/articles/benchmarking.html","id":"edgers-trimmed-mean-of-m-values","dir":"Articles","previous_headings":"A Review of MoR and TMM Normalization","what":"edgeR’s Trimmed Mean of M Values","title":"Benchmarking against DESeq2 and edgeR","text":"first “normalize” observed count profile sample total number counts N_i = \\sum_{g \\\\mathcal{G}} y_{,g} order get proportions: y'_{,g} = \\frac{y_{,g}}{N_i} next select reference sample ^{\\dagger} \\\\mathcal{} compute ratio log-transformed proportions weights: \\begin{aligned}     R_{,g} &= \\frac{\\log_2 y'_{,g}}{\\log_2 y'_{^{\\dagger}, g}} \\\\     w_{,g} &= \\frac{ N_i - Y_{,g} }{ N_i Y_{,g} } + \\frac{ N_{^{\\dagger}} - Y_{^{\\dagger},g} }{ N_{^{\\dagger}} Y_{^{\\dagger},g} } \\end{aligned} filter genes subset \\mathcal{G}'_i \\subset \\mathcal{G} symmetrically “trimming” away smallest largest ratios sample XX% original number (defaults 70%). finally compute size factor taking weighted average ratios raising second power: \\log_2 \\hat{s}_i = \\frac{ \\sum_{g \\\\mathcal{G}'_i} w_{,g} R_{,g} }{ \\sum_{g \\\\mathcal{G}'_i} w_{,g} }","code":""},{"path":[]},{"path":"https://toddmccready.github.io/disize/articles/benchmarking.html","id":"a-trivial-setting","dir":"Articles","previous_headings":"Benchmarking Size Factor Estimation","what":"A Trivial Setting","title":"Benchmarking against DESeq2 and edgeR","text":"","code":"#> Design Data:"},{"path":"https://toddmccready.github.io/disize/articles/benchmarking.html","id":"comparing-two-conditions","dir":"Articles","previous_headings":"Benchmarking Size Factor Estimation","what":"Comparing Two Conditions","title":"Benchmarking against DESeq2 and edgeR","text":"","code":"#> Design Data:"},{"path":[]},{"path":"https://toddmccready.github.io/disize/articles/comparing-defs.html","id":"reading-in-data","dir":"Articles","previous_headings":"","what":"Reading in data","title":"Comparing batch definitions","text":"","code":"# Grab filepaths counts_path <- system.file(     \"extdata\",     \"pasilla_gene_counts.tsv\",     package=\"pasilla\",     mustWork=TRUE ) metadata_path <- system.file(     \"extdata\",     \"pasilla_sample_annotation.csv\",     package=\"pasilla\",     mustWork=TRUE )  # Read in data counts <- as.matrix(read.csv(counts_path, sep = \"\\t\", row.names = \"gene_id\")) |>     t()  metadata <- read.csv(metadata_path) metadata <- metadata |>     dplyr::mutate(sample_id = sub(\"fb\", \"\", file)) |>     dplyr::select(sample_id, condition, type) |>     dplyr::mutate(dplyr::across(c(condition, type), as.factor))"},{"path":"https://toddmccready.github.io/disize/articles/comparing-defs.html","id":"inspecting-the-study-design","dir":"Articles","previous_headings":"","what":"Inspecting the study design","title":"Comparing batch definitions","text":"dataset derived study investigating effect various RNA binding proteins (RBPs) alternative splicing regulation. authors partitioned D. melanogaster cells two different conditions: samples condition = treated treated dsRNAs knockdown expression via RNAi, condition = untreated left alone control. Additionally, two sets duplicates processed condition different chemistry used sequencing (single-read vs paired-end). Therefore, suitable definition “batch” might grouping duplicates together: However, granular definition allow batch-effects even within duplicates: (Evidently one sample thrown away, although pose problem anything downstream.)","code":"metadata <- metadata |>     dplyr::mutate(id_1 = interaction(type, condition, sep = \":\")) metadata <- metadata |>     dplyr::mutate(id_2 = sample_id)  print(metadata) #>    sample_id condition        type                  id_1       id_2 #> 1   treated1   treated single-read   single-read:treated   treated1 #> 2   treated2   treated  paired-end    paired-end:treated   treated2 #> 3   treated3   treated  paired-end    paired-end:treated   treated3 #> 4 untreated1 untreated single-read single-read:untreated untreated1 #> 5 untreated2 untreated single-read single-read:untreated untreated2 #> 6 untreated3 untreated  paired-end  paired-end:untreated untreated3 #> 7 untreated4 untreated  paired-end  paired-end:untreated untreated4"},{"path":"https://toddmccready.github.io/disize/articles/comparing-defs.html","id":"estimating-size-factors","dir":"Articles","previous_headings":"","what":"Estimating size factors","title":"Comparing batch definitions","text":"absence batch-effects interested effects condition, design_formula : required arguments can now run disize batch definitions:","code":"design_formula <- ~ condition size_factors_1 <- disize::disize(     design_formula,     counts,     metadata,     batch_name = \"id_1\",     obs_name = \"sample_id\", # needed to order 'counts' correctly     n_threads = n_threads ) #> Formatting data... #> Estimating size factors... (Max ETA: ~14s) #> Finised in 14.5s!  size_factors_2 <- disize::disize(     design_formula,     counts,     metadata,     batch_name = \"id_2\",     obs_name = \"sample_id\",     n_threads = n_threads ) #> Formatting data... #> Estimating size factors... (Max ETA: ~18.7s) #> Finised in 14.8s!"},{"path":"https://toddmccready.github.io/disize/articles/comparing-defs.html","id":"comparing-definitions","dir":"Articles","previous_headings":"","what":"Comparing definitions","title":"Comparing batch definitions","text":"Although similarities (e.g., estimates untreated3 treated2 approximately equal), enough differences samples granular definition better choice analysis.","code":"size_factors <- data.frame(     sample_id = metadata$sample_id,     id_1 = unname(size_factors_1[metadata$id_1]),     id_2 = unname(size_factors_2[metadata$id_2]) )  print(size_factors) #>    sample_id       id_1        id_2 #> 1   treated1  0.3709355  0.43231922 #> 2   treated2 -0.3807361 -0.35853781 #> 3   treated3 -0.3807361 -0.27121098 #> 4 untreated1  0.2341333  0.04459051 #> 5 untreated2  0.2341333  0.50729254 #> 6 untreated3 -0.5046130 -0.51030155 #> 7 untreated4 -0.5046130 -0.36915601"},{"path":"https://toddmccready.github.io/disize/articles/comparing-defs.html","id":"running-deseq","dir":"Articles","previous_headings":"","what":"Running DESeq","title":"Comparing batch definitions","text":"size factors inserted DESeqDataSet object, analysis proceeds normally.","code":"# Constructing DESeqDataSet object dds <- DESeq2::DESeqDataSetFromMatrix(     countData = t(counts[metadata$sample_id, ]),     colData = metadata,     design = design_formula ) DESeq2::sizeFactors(dds) <- exp(size_factors_2) # Insert size factors  # Run analysis dds <- DESeq2::DESeq(dds) #> using pre-existing size factors #> estimating dispersions #> gene-wise dispersion estimates #> mean-dispersion relationship #> final dispersion estimates #> fitting model and testing  # Print results print(DESeq2::results(dds)) #> log2 fold change (MLE): condition untreated vs treated  #> Wald test p-value: condition untreated vs treated  #> DataFrame with 14599 rows and 6 columns #>                baseMean log2FoldChange     lfcSE       stat    pvalue      padj #>               <numeric>      <numeric> <numeric>  <numeric> <numeric> <numeric> #> FBgn0000003    0.187365    -1.03193740  3.804204 -0.2712624 0.7861892        NA #> FBgn0000008  103.057648     0.00258174  0.222254  0.0116161 0.9907319  0.997843 #> FBgn0000014    1.140011     0.51874750  2.111253  0.2457060 0.8059098        NA #> FBgn0000015    0.916010     1.88688061  2.062250  0.9149619 0.3602116        NA #> FBgn0000017 4713.919204     0.24364238  0.126651  1.9237327 0.0543881  0.279685 #> ...                 ...            ...       ...        ...       ...       ... #> FBgn0261571 9.27146e-02    -0.89084799  3.809351 -0.2338582  0.815095        NA #> FBgn0261572 6.71419e+00     0.96551977  0.763749  1.2641854  0.206163  0.598496 #> FBgn0261573 2.42783e+03    -0.00904066  0.117375 -0.0770239  0.938605  0.988237 #> FBgn0261574 5.25398e+03    -0.00675340  0.189429 -0.0356514  0.971560  0.993316 #> FBgn0261575 1.14935e+01    -0.14708285  0.924523 -0.1590905  0.873598  0.971324"},{"path":"https://toddmccready.github.io/disize/articles/disize.html","id":"an-example-with-deseq2","dir":"Articles","previous_headings":"","what":"An example with DESeq2","title":"An introduction to disize","text":"see disize action, analyzing following dataset Li et al., 2025 DESeq2. dataset consists purified macrophage subtype(“Mac2”, induced ‘activated’ state) partitioned four groups exposed different conditions. authors offer information samples processed: sorted Mac2 cells divided four groups stimulated 3-h time point concentrations previously described. , RNA extracted using RNeasy Plus Micro Kit per manufacturer instructions. Poly()mRNA isolated using mRNA Capture Beads 2.0 (Yeasen Cat.12629ES, CHN) two rounds purification, followed RNA fragmentation magnesium ions 94°C (Yeasen Cat.12340ES97, CHN). RNA sequencing library preparation performed using TruSeq RNA Library Prep Kit v2 (Illumina). Sequencing carried paired-end 2×150 bp (PE150) Illumina Novaseq™ X Plus (LC-Bio Technologies). TruSeq RNA Library Prep Kit involves “tagging” transcripts barcodes identify distinct samples, allowing prepared cDNA libraries pooled together sequencing. Since batch-effects usually attributed separate sequencing runs, expect small batch-effects present dataset define “batch” unit subjected RNA extraction (processing).","code":""},{"path":"https://toddmccready.github.io/disize/articles/disize.html","id":"dependencies","dir":"Articles","previous_headings":"An example with DESeq2","what":"Dependencies","title":"An introduction to disize","text":"","code":"suppressPackageStartupMessages({     library(disize)     library(curl)     library(R.utils)     library(data.table) })  # Set number of threads to use n_threads <- parallel::detectCores()"},{"path":"https://toddmccready.github.io/disize/articles/disize.html","id":"downloading-the-data","dir":"Articles","previous_headings":"An example with DESeq2","what":"Downloading the data","title":"An introduction to disize","text":"","code":"# Download counts and construct metadata counts_path <- curl::curl_download(     url = \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE273924&format=file&file=GSE273924%5Fraw%5Fcounts%2Etsv%2Egz\",     destfile = paste0(tempdir(), \"/counts.tsv.gz\") ) counts <- data.table::fread(counts_path)  metadata <- data.frame(     \"sample_id\" = c(colnames(counts)[-1]),     \"condition\" = factor(rep(c(\"control\", \"lps\", \"nelps\", \"ne\"), each = 3)) )  # Coerce to formatted matrix gene_names <- counts$gene_id counts <- t(as.matrix(counts[,-1])) colnames(counts) <- gene_names"},{"path":"https://toddmccready.github.io/disize/articles/disize.html","id":"running-disize","dir":"Articles","previous_headings":"An example with DESeq2","what":"Running disize","title":"An introduction to disize","text":"metadata contains information experimental design: dataset, study primarily interested effect condition expression, thus formula input disize : can finally run disize get estimated size factors: Evidently batch-effect indeed small across samples! samples “NELPS1” “NELPS2” seem processed slightly worse, otherwise estimated size factors approximately (within ~0.1). can confirm estimates rerunning disize larger n_feats: Indeed estimates remain largely .","code":"print(metadata) #>    sample_id condition #> 1      Ctrl1   control #> 2      Ctrl2   control #> 3      Ctrl3   control #> 4       LPS1       lps #> 5       LPS2       lps #> 6       LPS3       lps #> 7     NELPS1     nelps #> 8     NELPS2     nelps #> 9     NELPS3     nelps #> 10       NE1        ne #> 11       NE2        ne #> 12       NE3        ne design_formula <- ~ condition size_factors_1 <- disize::disize(     design_formula,     counts,     metadata,     batch_name = \"sample_id\",     n_threads = n_threads ) #> Formatting data... #> Estimating size factors... (Max ETA: ~32.5s) #> Finised in 12.4s! print(size_factors_1) #>        Ctrl1        Ctrl2        Ctrl3         LPS1         LPS2         LPS3  #>  0.086711573  0.010924573 -0.077573953  0.080145994  0.008387612  0.094615433  #>          NE1          NE2          NE3       NELPS1       NELPS2       NELPS3  #> -0.065187799  0.037279948  0.106725115 -0.164916966 -0.136815500 -0.025962074 size_factors_2 <- disize::disize(     design_formula,     counts,     metadata,     batch_name = \"sample_id\",     n_feats = 15000,     n_threads = n_threads ) #> Formatting data... #> Estimating size factors... (Max ETA: ~55.9s) #> Finised in 24.4s! print(size_factors_2) #>        Ctrl1        Ctrl2        Ctrl3         LPS1         LPS2         LPS3  #>  0.094264585  0.013007705 -0.070803021  0.069177987 -0.005185924  0.081820273  #>          NE1          NE2          NE3       NELPS1       NELPS2       NELPS3  #> -0.043598047  0.050039617  0.113597528 -0.173230185 -0.143794054 -0.031765591"},{"path":"https://toddmccready.github.io/disize/articles/disize.html","id":"running-deseq","dir":"Articles","previous_headings":"An example with DESeq2","what":"Running DESeq","title":"An introduction to disize","text":"size factors inserted DESeqDataSet object, analysis proceeds normally.","code":"# Constructing DESeqDataSet object dds <- DESeq2::DESeqDataSetFromMatrix(     countData = t(counts),     colData = metadata,     design = design_formula ) DESeq2::sizeFactors(dds) <- exp(size_factors_2) # Insert size factors  # Run analysis dds <- DESeq2::DESeq(dds) #> using pre-existing size factors #> estimating dispersions #> gene-wise dispersion estimates #> mean-dispersion relationship #> final dispersion estimates #> fitting model and testing  # Print results print(DESeq2::results(dds)) #> log2 fold change (MLE): condition nelps vs control  #> Wald test p-value: condition nelps vs control  #> DataFrame with 57132 rows and 6 columns #>                       baseMean log2FoldChange     lfcSE        stat      pvalue #>                      <numeric>      <numeric> <numeric>   <numeric>   <numeric> #> ENSMUSG00000028180 1.94153e+03     -0.7871862 0.0925976 -8.50114725 1.87726e-17 #> ENSMUSG00000028182 2.81686e+01     -0.8862797 0.5028262 -1.76259646 7.79686e-02 #> ENSMUSG00000028185 3.35066e-01     -0.0402415 4.4073563 -0.00913052 9.92715e-01 #> ENSMUSG00000028184 1.03779e+04      0.7660365 0.0651604 11.75617395 6.56420e-32 #> ENSMUSG00000028187 9.79170e+02     -0.1786587 0.1105460 -1.61614712 1.06063e-01 #> ...                        ...            ...       ...         ...         ... #> ENSMUSG00000106108   10.697655      6.7530320 1.4302308    4.721638 2.33953e-06 #> ENSMUSG00000042675 1581.164411     -0.0365519 0.0763698   -0.478617 6.32211e-01 #> ENSMUSG00000036959 1429.611296      0.5472422 0.0835722    6.548136 5.82596e-11 #> ENSMUSG00000036958    0.658051     -3.8966752 4.2776587   -0.910936 3.62329e-01 #> ENSMUSG00000042678    5.578372     -5.5971675 1.7015851   -3.289384 1.00407e-03 #>                           padj #>                      <numeric> #> ENSMUSG00000028180 1.75087e-16 #> ENSMUSG00000028182 1.51915e-01 #> ENSMUSG00000028185          NA #> ENSMUSG00000028184 1.03475e-30 #> ENSMUSG00000028187 1.97549e-01 #> ...                        ... #> ENSMUSG00000106108 9.56180e-06 #> ENSMUSG00000042675 7.67219e-01 #> ENSMUSG00000036959 3.62249e-10 #> ENSMUSG00000036958          NA #> ENSMUSG00000042678 2.93008e-03"},{"path":"https://toddmccready.github.io/disize/articles/implementation.html","id":"estimation","dir":"Articles","previous_headings":"","what":"Estimation","title":"Implementation of disize","text":"Since posterior distribution \\mathbf{s} heavily concentrated typical datasets thousands features, sufficient quickly provide point estimate \\mathbf{s} delegate estimation model coefficients existing tools like DESeq2 edgeR (replacing small normalization step workflows). disize uses Stan’s L-BFGS optimization algorithm find model’s maximum posteriori (MAP) \\mathbf{s}. end fewer iterations needed parameters converge using heuristic guess long procedure run ; followed diagnostic ensure size factors converged.","code":""},{"path":"https://toddmccready.github.io/disize/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Todd McCready. Author, maintainer.","code":""},{"path":"https://toddmccready.github.io/disize/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"McCready T (2025). disize: Design Informed Size Factor Estimation. R package version 0.5.0, https://toddmccready.github.io/disize/.","code":"@Manual{,   title = {disize: Design Informed Size Factor Estimation},   author = {Todd McCready},   year = {2025},   note = {R package version 0.5.0},   url = {https://toddmccready.github.io/disize/}, }"},{"path":"https://toddmccready.github.io/disize/index.html","id":"disize","dir":"","previous_headings":"","what":"Design Informed Size Factor Estimation","title":"Design Informed Size Factor Estimation","text":"existing methods RNAseq normalization DESeq2’s median ratios (MoR) edgeR’s trimmed mean M values (TMM) . methods however include information experimental design trying estimate size factors, can fail complex study designs. Design informed size factor estimation (disize) alternative normalization method jointly models gene expression batch-effects following specified design gain precision size factor estimates.","code":""},{"path":"https://toddmccready.github.io/disize/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Design Informed Size Factor Estimation","text":"Take look Get started page familiarize disize.","code":""},{"path":"https://toddmccready.github.io/disize/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Design Informed Size Factor Estimation","text":"disize yet CRAN, installation one-liner install.packages:","code":""},{"path":"https://toddmccready.github.io/disize/index.html","id":"with-remotes","dir":"","previous_headings":"","what":"With remotes","title":"Design Informed Size Factor Estimation","text":"","code":"# Install disize remotes::install_github(\"https://github.com/toddmccready/disize\")  # Set up CmdStan toolchain cmdstanr::install_cmdstan()"},{"path":"https://toddmccready.github.io/disize/index.html","id":"with-rv","dir":"","previous_headings":"","what":"With rv","title":"Design Informed Size Factor Estimation","text":"Add following entry rproject.toml file: install CmdStan toolchain R:","code":"dependencies = [     # ...     { name = \"disize\", git = \"https://github.com/toddmccready/disize\", branch = \"main\" },     # ... ] cmdstanr::install_cmdstan()"},{"path":"https://toddmccready.github.io/disize/reference/disize.html","id":null,"dir":"Reference","previous_headings":"","what":"Design-informed size factor estimation — disize","title":"Design-informed size factor estimation — disize","text":"Design-informed size factor estimation","code":""},{"path":"https://toddmccready.github.io/disize/reference/disize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Design-informed size factor estimation — disize","text":"","code":"disize(   design_formula,   counts,   metadata,   batch_name,   obs_name = \"obs_id\",   n_feats = min(10000L, ncol(counts)),   n_subset = 50L,   n_iters = 5000L,   rel_tol = 5000,   init_alpha = 1e-08,   history_size = 10L,   n_threads = 1L,   n_retries = 2L,   verbose = 3L )"},{"path":"https://toddmccready.github.io/disize/reference/disize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Design-informed size factor estimation — disize","text":"design_formula formula describing experimental design. counts (observation x feature) count matrix. metadata dataframe containing observation-level metadata. batch_name identifier batch column 'metadata'. obs_name identifier observation column 'metadata'. n_feats number features used estimation. n_subset number observations per experimental unit used estimation, defaults 50 (useful scRNA-seq experiments). n_iters number iterations used estimation. rel_tol relative tolerance used convergence. init_alpha initial step-size optimizer, lower values can sometimes make easier estimate size factors complex designs. history_size number past updates use L-BFGS algorithm. n_threads number threads use parallel processing. n_retries maximum number times retry fitting. verbose verbosity level (1: errors, 2: also allows warnings, 3: also allows messages, 4: also prints additional output useful debugging).","code":""},{"path":"https://toddmccready.github.io/disize/reference/disize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Design-informed size factor estimation — disize","text":"named numeric vector containing size factor estimates.","code":""}]
